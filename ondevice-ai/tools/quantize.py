# tools/quantize.py
"""
Placeholder for model quantization utilities. In a real setup, this would
convert a float32 model to MLX-quantized formats (e.g., 4-bit/8-bit).
"""

if __name__ == "__main__":
    print("Quantization placeholder: provide model path and target format.")
